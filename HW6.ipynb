{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1c5ccc",
   "metadata": {},
   "source": [
    "1.ChatBot History: https://chatgpt.com/share/672d960f-54cc-8000-b150-719471b9a1e8\n",
    "In Simple Linear Regression, we predict an outcome Y from a predictor x with the equation Y = β0 + β1x + ϵ, where β0 is the intercept, β1 is the slope, and ϵ is random error. The line β0 + β1x shows the expected trend in Y, while the error term adds realistic variation, forming a spread of points around the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64801369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Parameters for the theoretical SLR model\n",
    "n = 100  # Number of data points\n",
    "beta0 = 2  # Intercept\n",
    "beta1 = 1.5  # Slope\n",
    "sigma = 1  # Standard deviation of error\n",
    "\n",
    "# Step 1: Generate predictor values, xi\n",
    "np.random.seed(0)\n",
    "x = stats.uniform.rvs(0, 10, size=n)\n",
    "\n",
    "# Step 2: Generate error terms, εi ~ N(0, σ^2)\n",
    "errors = stats.norm.rvs(0, sigma, size=n)\n",
    "\n",
    "# Step 3: Calculate outcome values, Yi = β0 + β1 * xi + εi\n",
    "Y = beta0 + beta1 * x + errors\n",
    "\n",
    "# Step 4: Visualize the theoretical linear model and data points\n",
    "# Creating the line Y = β0 + β1 * x for visual reference\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_line = beta0 + beta1 * x_line\n",
    "\n",
    "# Plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Scatter plot of simulated data points\n",
    "fig.add_trace(go.Scatter(x=x, y=Y, mode='markers', name='Data'))\n",
    "\n",
    "# Line representing the theoretical linear relationship\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines', name='Theoretical Line', line=dict(color='red')))\n",
    "\n",
    "# Labels and title\n",
    "fig.update_layout(title='Theoretical Simple Linear Regression Model',\n",
    "                 xaxis_title='Predictor x',\n",
    "                 yaxis_title='Outcome Y')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf  # Used for specifying and fitting statistical models\n",
    "import plotly.express as px  # Used for creating visualizations\n",
    "\n",
    "# Set parameters for the simulated data\n",
    "n = 100  # Number of data points\n",
    "beta0 = 2  # Intercept\n",
    "beta1 = 1.5  # Slope\n",
    "sigma = 1  # Standard deviation of the error term\n",
    "\n",
    "# Generate predictor variable x and outcome variable Y\n",
    "np.random.seed(0)\n",
    "x = np.random.uniform(0, 10, n)\n",
    "errors = np.random.normal(0, sigma, n)\n",
    "Y = beta0 + beta1 * x + errors\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\n",
    "\n",
    "# Specify and fit the Simple Linear Regression model\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)  # Specify the model with 'Y ~ x'\n",
    "fitted_model = model_data_specification.fit()  # Fit the model to get regression results\n",
    "\n",
    "# Output model results\n",
    "print(fitted_model.summary())  # Display the full summary of regression results\n",
    "print(fitted_model.summary().tables[1])  # Display the table of estimated coefficients and statistics\n",
    "print(\"Model Parameters:\", fitted_model.params)  # Display the estimated model parameters (intercept and slope)\n",
    "print(\"Parameter Values:\", fitted_model.params.values)  # Extract the values of the model parameters\n",
    "print(\"R-squared:\", fitted_model.rsquared)  # Display R-squared, measuring the explanatory power of x for Y\n",
    "\n",
    "# Visualize the fitted linear model\n",
    "df['Data'] = 'Data'  # Adds a label to the data points for the legend\n",
    "\n",
    "# Plot the scatter plot with a trendline\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', trendline='ols', title='Y vs. x')\n",
    "\n",
    "# Manually overlay the trendline\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues,\n",
    "                line=dict(color='blue'), name=\"trendline='ols'\")\n",
    "\n",
    "# Display the figure (use fig.show(renderer=\"png\") for submissions on GitHub or MarkUs)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a3bdf",
   "metadata": {},
   "source": [
    "3.\n",
    "1)Theoretical Line (Orange, Dotted): This line shows the “true” relationship we set up between x and Y using fixed values for the intercept and slope (beta0 and beta1). It represents the pattern we expect in Y based on x without any randomness. Think of it as the ideal trend.\n",
    "\n",
    "2)Fitted Line (Blue, Solid): This line shows the relationship between x and Y in the sample of data we generated, which includes some randomness (noise). Because we added random errors to each point when we created Y, the actual data points don’t line up perfectly along the theoretical line. So, when we fit a regression line to this sample data, it’s close to the theoretical line but not exactly the same. This fitted line varies slightly because each sample of data is different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f3d5d",
   "metadata": {},
   "source": [
    "4.\n",
    "The fitted_model.fittedvalues represent the predicted y^i values for each data point based on the estimated coefficients from the fitted Simple Linear Regression model. These coefficients, β^0 (intercept) and β^1 (slope), are obtained from fitted_model.params, which stores the estimated parameters. The fitted values are calculated using the formula y^i = β^0 + β^1xi, where xi is the predictor value for each observation. Essentially, fitted_model.fittedvalues provides the predicted values of y based on the regression equation derived from the sample data, allowing us to see how the model fits the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7c17f",
   "metadata": {},
   "source": [
    "5.\n",
    "The fitted line in Ordinary Least Squares (OLS) regression is the one that minimizes the sum of the squared differences between the observed y-values and the predicted y^i-values (the residuals). This method uses \"squares\" because squaring the residuals ensures that both positive and negative errors are treated equally and avoids cancellation, while giving more weight to larger errors. By minimizing the squared residuals, OLS finds the line that best represents the relationship between the predictor and outcome variables, providing the most accurate predictions given the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c5fd7",
   "metadata": {},
   "source": [
    "6.\n",
    "The first expression represents the R squared value, which quantifies the proportion of variation in Y explained by the model's fitted values (Y^). R squared, found in fitted_model.rsquared, is a measure of the model's accuracy, with higher values indicating better model fit. The two np.corrcoef(...)[0,1]**2 expressions capture the squared correlation between Y and the fitted values (which equals R squared, showing how well the model explains Y) and between Y and the predictor x, showing how much of the variation in Y is due to x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96182c7d",
   "metadata": {},
   "source": [
    "7.\n",
    "This dataset violates two key assumptions of the Simple Linear Regression (SLR) model. First, the assumption of linearity does not hold, as the relationship between fertilizer amount and crop yield appears non-linear, with yield increasing more sharply at higher fertilizer levels. Second, the residuals are not normally distributed, as shown by the skewed histogram, which suggests non-normality. These issues indicate that a non-linear or polynomial model may better fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0eaab7",
   "metadata": {},
   "source": [
    "8.\n",
    "Null Hypothesis (H₀): There is no linear association (on average) between waiting time and eruption duration. This implies that the slope parameter, β1, of the Simple Linear Regression model is zero: β1=0.\n",
    "\n",
    "Based on the p-value obtained from the regression analysis, we can characterize the evidence in the data relative to the null hypothesis that there is no linear relationship between the waiting time and the duration of the Old Faithful Geyser eruptions. If the p-value is small (e.g., less than 0.05), we would reject the null hypothesis, suggesting a statistically significant linear relationship between the two variables. On the other hand, if the p-value is large (e.g., greater than 0.1), we would fail to reject the null hypothesis, indicating that there is insufficient evidence to claim a linear association. The strength of the evidence is determined by how small the p-value is, with values closer to 0 providing stronger evidence against the null hypothesis.\n",
    "\n",
    "Based on the p-value from the regression analysis, my beliefs regarding the Old Faithful Geyser dataset are as follows: If the p-value is small (e.g., < 0.05), I would believe there is a statistically significant linear relationship between waiting time and eruption duration, suggesting that waiting time affects the duration. If the p-value is large (e.g., > 0.1), I would believe there is no strong evidence for such a relationship, implying that waiting time does not meaningfully predict eruption duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# The \"Classic\" Old Faithful Geyser dataset\n",
    "old_faithful = sns.load_dataset('geyser')\n",
    "\n",
    "# Specify the linear model\n",
    "linear_for_specification = 'duration ~ waiting'\n",
    "\n",
    "# Fit the model\n",
    "model = smf.ols(linear_for_specification, data=old_faithful)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Display the summary of the fitted model\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54456aa3",
   "metadata": {},
   "source": [
    "9.\n",
    "To determine if there is evidence of a relationship between duration and waiting for short wait times (e.g., less than 62, 64, or 66 minutes), we compare the p-value for the slope coefficient from the regression model run on the short wait times subset with that from the full dataset. If the p-value for short wait times is similarly small (e.g., < 0.05) as the p-value for the full dataset, it suggests that the linear relationship between waiting and duration holds in both cases. If the p-value for short wait times is larger, we fail to reject the null hypothesis, indicating that there is no significant relationship between waiting and duration for short wait times.\n",
    "\n",
    "By examining the p-values for each short_wait_limit value, we can determine the strength of the evidence against the null hypothesis. If the p-value is small (below 0.05), it suggests a statistically significant relationship between waiting and duration for short wait times. If the p-value is larger, we fail to reject the null hypothesis, suggesting no significant linear relationship for that subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58708218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define the short wait limits\n",
    "short_wait_limits = [62, 64, 66]\n",
    "\n",
    "for short_wait_limit in short_wait_limits:\n",
    "    # Filter the data for short waiting times\n",
    "    short_wait = old_faithful.waiting < short_wait_limit\n",
    "    \n",
    "    # Perform OLS regression\n",
    "    result = smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit()\n",
    "    \n",
    "    # Print the summary of the regression to get p-value\n",
    "    print(f\"Short wait limit: {short_wait_limit}\")\n",
    "    print(result.summary().tables[1])  # p-value for the slope coefficient\n",
    "    \n",
    "    # Create a scatter plot with the linear regression trendline\n",
    "    fig = px.scatter(old_faithful[short_wait], x='waiting', y='duration', \n",
    "                     title=f\"Old Faithful Geyser Eruptions for short wait times (<{short_wait_limit})\", \n",
    "                     trendline='ols')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "import seaborn as sns\n",
    "old_faithful = sns.load_dataset('geyser')\n",
    "\n",
    "# Define the long wait times (long_wait_limit = 71)\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# Define the number of bootstrap samples\n",
    "n_bootstrap = 1000\n",
    "\n",
    "# Create a list to store bootstrapped slope coefficients\n",
    "bootstrapped_slope_coefficients = []\n",
    "\n",
    "# Bootstrap sampling and fitting Simple Linear Regression\n",
    "for _ in range(n_bootstrap):\n",
    "    bootstrap_sample = old_faithful[long_wait].sample(n=long_wait.sum(), replace=True)\n",
    "    model = smf.ols('duration ~ waiting', data=bootstrap_sample)\n",
    "    fitted_model = model.fit()\n",
    "    bootstrapped_slope_coefficients.append(fitted_model.params[1])\n",
    "\n",
    "# Convert the list of bootstrapped slopes to a numpy array\n",
    "bootstrapped_slope_coefficients = np.array(bootstrapped_slope_coefficients)\n",
    "\n",
    "# Plot the bootstrapped sampling distribution of the fitted slope coefficients\n",
    "fig = px.histogram(bootstrapped_slope_coefficients, nbins=30, title=\"Bootstrapped Sampling Distribution of the Slope Coefficients\")\n",
    "fig.show()\n",
    "\n",
    "# 95% bootstrapped confidence interval for the slope coefficients\n",
    "bootstrapped_conf_interval = np.quantile(bootstrapped_slope_coefficients, [0.025, 0.975])\n",
    "print(f\"95% Bootstrapped Confidence Interval for the Slope Coefficients: {bootstrapped_conf_interval}\")\n",
    "\n",
    "# Simulate data under the null hypothesis (no linear association)\n",
    "# Parameters: β0 = 1.65, β1 = 0, σ = 0.37\n",
    "n_simulations = 1000\n",
    "simulated_slope_coefficients = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    # Simulate the 'duration' values under the null hypothesis assumption\n",
    "    old_faithful_simulation = old_faithful[long_wait].copy()\n",
    "    old_faithful_simulation['duration'] = 1.65 + 0 * old_faithful_simulation.waiting + stats.norm(loc=0, scale=0.37).rvs(size=long_wait.sum())\n",
    "    \n",
    "    # Fit a Simple Linear Regression model to the simulated data\n",
    "    model = smf.ols('duration ~ waiting', data=old_faithful_simulation)\n",
    "    fitted_model = model.fit()\n",
    "    simulated_slope_coefficients.append(fitted_model.params[1])\n",
    "\n",
    "# Convert the list of simulated slopes to a numpy array\n",
    "simulated_slope_coefficients = np.array(simulated_slope_coefficients)\n",
    "\n",
    "# Plot the simulated sampling distribution of the slope coefficients under the null hypothesis\n",
    "fig = px.histogram(simulated_slope_coefficients, nbins=30, title=\"Simulated Sampling Distribution of the Slope Coefficients (Null Hypothesis)\")\n",
    "fig.show()\n",
    "\n",
    "# Calculate the p-value for the simulated slope coefficients\n",
    "observed_slope = smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().params[1]\n",
    "simulated_p_value = (np.abs(simulated_slope_coefficients) >= np.abs(observed_slope)).mean()\n",
    "print(f\"Simulated p-value under the null hypothesis: {simulated_p_value}\")\n",
    "\n",
    "# Check if 0 is within the 95% confidence interval for the bootstrapped slope coefficients\n",
    "contains_zero = (bootstrapped_conf_interval[0] <= 0 <= bootstrapped_conf_interval[1])\n",
    "print(f\"Does the 95% bootstrapped confidence interval contain 0? {contains_zero}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105da0ba",
   "metadata": {},
   "source": [
    "11.ChatBot History: https://chatgpt.com/share/6730739c-9528-8000-9386-69c9377a4aee\n",
    "The indicator variable model compares eruption durations between short and long wait times, assuming different effects for each group. In contrast, the simple linear regression models treat waiting time as continuous, assuming a consistent linear relationship with eruption duration. The indicator model is useful for group differences, while the linear models are for continuous relationships.\n",
    "\n",
    "\n",
    "If we check the p-value for the C(kind)[T.long] coefficient in the regression summary:\n",
    "\n",
    "1)If p < 0.05, we reject the null hypothesis, indicating there is significant evidence to suggest that the eruption duration differs between the \"short\" and \"long\" wait time groups.\n",
    "\n",
    "2)If p ≥ 0.05, we fail to reject the null hypothesis, indicating there is insufficient evidence to claim a difference between the groups.\n",
    "\n",
    "The specific p-value will determine whether the difference between the \"short\" and \"long\" wait times is statistically significant. Without the actual regression output, I can't provide the exact value, but based on the model specification, you should check the p-value for kind[T.long] to interpret the evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f96372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from IPython.display import display\n",
    "\n",
    "# Fit the model with the indicator variable 'kind' (short vs. long)\n",
    "display(smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit().summary().tables[1])\n",
    "\n",
    "# Create a box plot to visualize the differences in duration by 'kind'\n",
    "import plotly.express as px\n",
    "fig = px.box(old_faithful, x='kind', y='duration', \n",
    "             title='duration ~ kind',\n",
    "             category_orders={'kind': ['short', 'long']})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda348b3",
   "metadata": {},
   "source": [
    "12.\n",
    "Model 2 (Short Wait Data) is the most likely to suggest that the distribution of residuals is normal. This is because the smaller bin size may reveal more subtle features of the residuals, and if they appear roughly symmetric and bell-shaped, this would support the assumption of normality.\n",
    "Models 1, 3, and 4 do not support the assumption of normality, as they are more likely to show skewness, heavy tails, or clustering, suggesting that the models may not fully account for the data patterns, and alternative models or transformations might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2ad7d",
   "metadata": {},
   "source": [
    "13.ChatBot History: https://chatgpt.com/share/6730739c-9528-8000-9386-69c9377a4aee\n",
    "(a)Permutation testing and bootstrap sampling are two different resampling techniques used for hypothesis testing and estimating confidence intervals, respectively. In permutation testing, the null hypothesis assumes no difference between groups, and group labels are shuffled to create a distribution of mean differences under this assumption. The observed mean difference is then compared to this distribution to calculate a p-value. In contrast, bootstrap sampling involves resampling with replacement within each group to create many new samples, allowing for the estimation of the sampling distribution of the mean difference and the creation of a confidence interval. The key difference is that permutation tests focus on hypothesis testing, while bootstrap sampling estimates the distribution and confidence intervals for a statistic.\n",
    "\n",
    "(b)\n",
    "Similarities:\n",
    " 1)Goal: All three methods aim to test whether there is a significant difference in mean duration between the \"short\" and \"long\" wait time groups.\n",
    " \n",
    " 2)Null Hypothesis: The null hypothesis in all three methods is that there is no difference in mean durations between the two groups (i.e., H0: μshort = μlong).\n",
    " \n",
    " 3)Comparison of Groups: All methods ultimately compare the means of the two groups and assess the statistical significance of any observed difference.\n",
    " \n",
    " \n",
    "Differences:\n",
    " 1)Methodology:\n",
    "   ·The indicator variable model uses a fixed regression model to compare the two groups and test the difference based on the regression coefficient for the \"long\" group.\n",
    "   ·The permutation test uses data shuffling to create a distribution of mean differences under the null hypothesis, avoiding reliance on model assumptions.\n",
    "   ·The bootstrap sampling creates many resamples of the data to estimate the sampling distribution of the mean difference and constructs a confidence interval based on these resamples.\n",
    " \n",
    " 2)Assumptions:\n",
    "   ·The indicator variable model assumes the linear regression model is appropriate (including normality and homogeneity of variance).\n",
    "   ·The permutation test makes no assumptions about the data distribution and is non-parametric.\n",
    "   ·The bootstrap sampling assumes that the observed data is representative of the population but is robust to non-normality and outliers.\n",
    " \n",
    " 3)Result:\n",
    "   ·The indicator variable model provides a p-value directly based on the significance of the regression coefficient for the \"long\" group.\n",
    "   ·The permutation test generates a p-value by comparing the observed mean difference with the distribution of permuted differences.\n",
    "   ·The bootstrap sampling provides a confidence interval for the mean difference, which can be used to infer significance if zero is outside the interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5cacc",
   "metadata": {},
   "source": [
    "14.Yes, I have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882b5b0c",
   "metadata": {},
   "source": [
    "I am very sorry for the late submission. I keep trying to commit but when I download the finished job file it keeps showing up as a blank file. I explained this to my ta in the tutorial on Friday. Now I can finally submit it successfully. Sorry again for the late submission and the inconvenience caused to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
